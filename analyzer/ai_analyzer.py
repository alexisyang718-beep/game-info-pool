"""
AI åˆ†ææ¨¡å—
ä½¿ç”¨ MiniMax API ç”Ÿæˆç»“æ„åŒ–çš„å¼‚åŠ¨åˆ†ææŠ¥å‘Šï¼š
- ä¸Šå‡å¼‚åŠ¨ï¼šæ’åæ˜¾è‘—ä¸Šå‡çš„æ¸¸æˆ
- ä¸‹é™å¼‚åŠ¨ï¼šæ’åæ˜¾è‘—ä¸‹é™çš„æ¸¸æˆ
- æ–°è¿›æ¦œï¼šæ–°ä¸Šæ¦œçš„æ¸¸æˆ
- åœ°åŒºè¶‹åŠ¿ï¼šå„åœ°åŒºè§„å¾‹æˆ–å·®å¼‚
- å“ç±»åŠ¨å‘ï¼šå“ç±»èµ°åŠ¿åˆ†æ
- è¡Œä¸šåŠ¨æ€ï¼šç›¸å…³è¡Œä¸šèƒŒæ™¯
"""

import os
import json
import requests
from collections import defaultdict
from datetime import datetime

MINIMAX_API_KEY = os.environ.get("MINIMAX_API_KEY", "")
MINIMAX_API_URL = "https://api.minimax.chat/v1/text/chatcompletion_v2"


def call_minimax(prompt: str, system_prompt: str = "") -> str:
    """è°ƒç”¨ MiniMax API"""
    if not MINIMAX_API_KEY:
        return "[æœªé…ç½® MINIMAX_API_KEYï¼Œè·³è¿‡ AI åˆ†æ]"

    headers = {
        "Authorization": f"Bearer {MINIMAX_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "abab6.5s-chat",
        "messages": [
            {"role": "system", "content": system_prompt or "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ‰‹æ¸¸å¸‚åœºåˆ†æå¸ˆã€‚"},
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.5,
        "max_tokens": 2000,
    }
    try:
        resp = requests.post(MINIMAX_API_URL, headers=headers, json=payload, timeout=60)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[AI åˆ†æå¤±è´¥: {e}]"


def build_chart_summary(chart_data: list[dict]) -> str:
    """
    æ„å»ºç¬¬ä¸€éƒ¨åˆ†ï¼šå„æ¸ é“ Top5 æ¦œå•æ¦‚è¦æ–‡æœ¬ï¼ˆä¾› AI æ‰©å†™ï¼‰
    æ ¼å¼ï¼šåœ°åŒº > æ¦œå•ç±»å‹ > Top5
    """
    # æŒ‰ (store, chart_name, region_name) åˆ†ç»„ï¼Œå– Top5
    groups = defaultdict(list)
    for app in chart_data:
        key = (app.get("store", "appstore"), app.get("chart_name", ""), app.get("region_name", ""))
        groups[key].append(app)

    lines = []
    # æŒ‰å•†åº—ã€æ¦œå•ç±»å‹ã€åœ°åŒºæ’åºè¾“å‡º
    store_order = {"appstore": 0, "google_play": 1}
    chart_order = {"å…è´¹æ¸¸æˆæ¦œ": 0, "ä»˜è´¹æ¸¸æˆæ¦œ": 1, "ç•…é”€æ¦œ": 2}

    sorted_keys = sorted(
        groups.keys(),
        key=lambda k: (store_order.get(k[0], 9), chart_order.get(k[1], 9), k[2])
    )

    for store, chart_name, region in sorted_keys:
        store_label = "App Store" if store == "appstore" else "Google Play"
        apps = sorted(groups[(store, chart_name, region)], key=lambda x: x.get("rank", 999))[:5]
        top5 = " / ".join([f"#{a['rank']} {a['name']}" for a in apps])
        lines.append(f"[{store_label}Â·{region}Â·{chart_name}] {top5}")

    return "\n".join(lines)


def analyze_changes(changes: list[dict], news_list: list = None) -> dict:
    """
    ç”Ÿæˆç»“æ„åŒ–çš„å¼‚åŠ¨åˆ†ææŠ¥å‘Š
    è¿”å›åŒ…å«æ¨¡å—çš„å­—å…¸ï¼šrising, falling, new_entries, regions, categories, industry
    """
    if not changes:
        return {
            "rising": [],
            "falling": [],
            "new_entries": [],
            "regions": "ä»Šæ—¥æš‚æ— æ˜¾è‘—æ¦œå•å¼‚åŠ¨ã€‚",
            "categories": "ä»Šæ—¥æš‚æ— æ˜¾è‘—æ¦œå•å¼‚åŠ¨ã€‚",
            "industry": ""
        }

    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    news_text = ""
    if news_list:
        from scrapers.news_scraper import format_news_for_ai
        news_text = format_news_for_ai(news_list)

    # æ•´ç†å¼‚åŠ¨æ•°æ®
    change_lines = []
    for c in changes[:30]:
        region = c.get("region_name", "")
        store = "App Store" if c.get("store", "") != "google_play" else "Google Play"
        change_type = c["change_type"]
        name = c["name"]
        artist = c.get("artist", "")
        if change_type == "æ–°è¿›æ¦œ":
            change_lines.append(f"- {region}/{store}: ã€Š{name}ã€‹({artist}) æ–°è¿›æ¦œ #{c['rank_today']}")
        elif change_type == "é€€æ¦œ":
            change_lines.append(f"- {region}/{store}: ã€Š{name}ã€‹({artist}) é€€æ¦œï¼ˆæ˜¨æ—¥#{c['rank_yesterday']}ï¼‰")
        else:
            delta = abs(c.get("rank_delta", 0))
            change_lines.append(
                f"- {region}/{store}: ã€Š{name}ã€‹({artist}) {change_type} {delta}ä½ "
                f"ï¼ˆ#{c['rank_yesterday']}â†’#{c['rank_today']}ï¼‰"
            )

    changes_text = "\n".join(change_lines)

    news_section = f"""
**æœ€æ–°è¡Œä¸šæ–°é—»ï¼ˆä¾›å‚è€ƒï¼‰ï¼š**
{news_text}
""" if news_text else ""

    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹ {today} æ‰‹æ¸¸æ¦œå•å¼‚åŠ¨æ•°æ®åŠè¡Œä¸šæ–°é—»ï¼Œç”Ÿæˆç»“æ„åŒ–çš„å¼‚åŠ¨åˆ†æã€‚

**ä»Šæ—¥æ¦œå•å¼‚åŠ¨ï¼š**
{changes_text}
{news_section}
---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ï¼š

{{
  "rising": [
    {{
      "game": "æ¸¸æˆå",
      "change": "ä¸Šå‡50ä½ï¼ˆ#60â†’#10ï¼‰",
      "region": "ç¾å›½",
      "store": "App Store",
      "analysis": "ç®€çŸ­åˆ†æåŸå› ï¼Œ50å­—ä»¥å†…"
    }}
  ],
  "falling": [
    {{
      "game": "æ¸¸æˆå",
      "change": "ä¸‹é™30ä½ï¼ˆ#5â†’#35ï¼‰",
      "region": "ç¾å›½",
      "store": "App Store",
      "analysis": "ç®€çŸ­åˆ†æåŸå› ï¼Œ50å­—ä»¥å†…"
    }}
  ],
  "new_entries": [
    {{
      "game": "æ¸¸æˆå",
      "change": "æ–°è¿›æ¦œ #1",
      "region": "ç¾å›½",
      "store": "App Store",
      "analysis": "ç®€çŸ­åˆ†æåŸå› ï¼Œ50å­—ä»¥å†…"
    }}
  ],
  "regions": "â€¢ è¦ç‚¹ä¸€ï¼šå…·ä½“å†…å®¹\\n\\nâ€¢ è¦ç‚¹äºŒï¼šå…·ä½“å†…å®¹\\n\\nâ€¢ è¦ç‚¹ä¸‰ï¼šå…·ä½“å†…å®¹",
  "categories": "â€¢ è¦ç‚¹ä¸€ï¼šå…·ä½“å†…å®¹\\n\\nâ€¢ è¦ç‚¹äºŒï¼šå…·ä½“å†…å®¹\\n\\nâ€¢ è¦ç‚¹ä¸‰ï¼šå…·ä½“å†…å®¹",
  "industry": "â€¢ è¦ç‚¹ä¸€ï¼šå…·ä½“å†…å®¹\\n\\nâ€¢ è¦ç‚¹äºŒï¼šå…·ä½“å†…å®¹ï¼ˆå¦‚æ— ç›¸å…³æ–°é—»åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰"
}}

è¦æ±‚ï¼š
1. rising æ•°ç»„ï¼šæ’åä¸Šå‡çš„æ¸¸æˆï¼Œé€‰å– 2-3 ä¸ªæœ€æ˜¾è‘—çš„
2. falling æ•°ç»„ï¼šæ’åä¸‹é™çš„æ¸¸æˆï¼Œé€‰å– 2-3 ä¸ªæœ€æ˜¾è‘—çš„
3. new_entries æ•°ç»„ï¼šæ–°è¿›æ¦œçš„æ¸¸æˆï¼Œé€‰å– 2-3 ä¸ªæœ€é‡è¦çš„
4. æ¯ä¸ª analysis è¦ç®€æ´æœ‰åŠ›ï¼Œç‚¹æ˜å…³é”®åŸå› 
5. regionsã€categoriesã€industry å¿…é¡»åˆ†ç‚¹é™ˆè¿°ï¼š
   - æ¯ä¸ªè¦ç‚¹ä»¥"â€¢"å¼€å¤´
   - æ¯ä¸ªè¦ç‚¹ä¹‹é—´ç”¨"\\n\\n"åˆ†éš”ï¼ˆç©ºä¸€è¡Œï¼‰
   - æ¯ä¸ªæ¨¡å— 2-3 ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡ 30 å­—
6. regions è¦æç‚¼å„åœ°åŒºçš„å…±æ€§å’Œå·®å¼‚
7. categories è¦æŒ‡å‡ºå“ªäº›å“ç±»åœ¨ä¸Šå‡/ä¸‹é™
8. åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—
"""

    system = "ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„æ‰‹æ¸¸å¸‚åœºåˆ†æå¸ˆã€‚è¯·åŸºäºæ•°æ®å’Œæ–°é—»ç»™å‡ºä¸“ä¸šã€åŠ¡å®çš„åˆ†æã€‚åªè¾“å‡ºåˆæ³•çš„ JSON æ ¼å¼ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
    
    result = call_minimax(prompt, system)
    
    # è§£æ JSON ç»“æœ
    try:
        # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
        if "```json" in result:
            result = result.split("```json")[1].split("```")[0]
        elif "```" in result:
            result = result.split("```")[1].split("```")[0]
        
        parsed = json.loads(result.strip())
        return {
            "rising": parsed.get("rising", []),
            "falling": parsed.get("falling", []),
            "new_entries": parsed.get("new_entries", []),
            "regions": parsed.get("regions", ""),
            "categories": parsed.get("categories", ""),
            "industry": parsed.get("industry", "")
        }
    except (json.JSONDecodeError, IndexError, KeyError) as e:
        # JSON è§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ä½œä¸º fallback
        print(f"[Warning] AI è¿”å›é JSON æ ¼å¼ï¼Œä½¿ç”¨ fallback: {e}")
        return {
            "rising": [],
            "falling": [],
            "new_entries": [],
            "regions": result if result else "åˆ†æç”Ÿæˆå¤±è´¥",
            "categories": "",
            "industry": "",
            "raw_text": result  # ä¿ç•™åŸå§‹æ–‡æœ¬ä¾›è°ƒè¯•
        }


def analyze_changes_text(changes: list[dict], news_list: list = None) -> str:
    """
    ç”Ÿæˆçº¯æ–‡æœ¬æ ¼å¼çš„å¼‚åŠ¨åˆ†æï¼ˆç”¨äº Excel å’Œä¼ä¸šå¾®ä¿¡ï¼‰
    """
    analysis = analyze_changes(changes, news_list)
    
    lines = ["## å¼‚åŠ¨åˆ†æï¼ˆå¯¹æ¯”æ˜¨æ—¥ï¼‰\n"]
    
    # ä¸Šå‡
    if analysis.get("rising"):
        lines.append("### ğŸ“ˆ ä¸Šå‡")
        for h in analysis["rising"]:
            lines.append(f"- **ã€Š{h.get('game', '')}ã€‹** {h.get('change', '')}ï¼ˆ{h.get('region', '')} Â· {h.get('store', '')}ï¼‰")
            lines.append(f"  {h.get('analysis', '')}")
        lines.append("")
    
    # ä¸‹é™
    if analysis.get("falling"):
        lines.append("### ğŸ“‰ ä¸‹é™")
        for h in analysis["falling"]:
            lines.append(f"- **ã€Š{h.get('game', '')}ã€‹** {h.get('change', '')}ï¼ˆ{h.get('region', '')} Â· {h.get('store', '')}ï¼‰")
            lines.append(f"  {h.get('analysis', '')}")
        lines.append("")
    
    # æ–°è¿›æ¦œ
    if analysis.get("new_entries"):
        lines.append("### ğŸ†• æ–°è¿›æ¦œ")
        for h in analysis["new_entries"]:
            lines.append(f"- **ã€Š{h.get('game', '')}ã€‹** {h.get('change', '')}ï¼ˆ{h.get('region', '')} Â· {h.get('store', '')}ï¼‰")
            lines.append(f"  {h.get('analysis', '')}")
        lines.append("")
    
    # åœ°åŒºè¶‹åŠ¿
    if analysis.get("regions"):
        lines.append("### åœ°åŒºè¶‹åŠ¿")
        lines.append(analysis["regions"])
        lines.append("")
    
    # å“ç±»åŠ¨å‘
    if analysis.get("categories"):
        lines.append("### å“ç±»åŠ¨å‘")
        lines.append(analysis["categories"])
        lines.append("")
    
    # è¡Œä¸šåŠ¨æ€
    if analysis.get("industry"):
        lines.append("### è¡Œä¸šåŠ¨æ€")
        lines.append(analysis["industry"])
    
    # å¦‚æœæœ‰åŸå§‹æ–‡æœ¬ fallback
    if analysis.get("raw_text") and not analysis.get("rising") and not analysis.get("falling") and not analysis.get("new_entries"):
        return analysis["raw_text"]
    
    return "\n".join(lines)


def generate_chart_summary_text(chart_data: list[dict], news_list: list = None) -> str:
    """
    ç”Ÿæˆç¬¬ä¸€éƒ¨åˆ†ï¼šæ¦œå•æ¦‚è¦
    ç›´æ¥åŸºäºæ•°æ®ç”Ÿæˆï¼Œä¸è°ƒç”¨ AIï¼ˆèŠ‚çœ tokenï¼‰
    """
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    summary = build_chart_summary(chart_data)

    # ç»Ÿè®¡åŸºæœ¬æ•°å­—
    stores = set(a.get("store") for a in chart_data)
    regions = set(a.get("region_name") for a in chart_data)
    total = len(chart_data)

    header = f"""## ç¬¬ä¸€éƒ¨åˆ†ï¼š{today} æ¦œå•æ¦‚è¦

**æ•°æ®æ¦‚è§ˆ**
- è¦†ç›–å•†åº—ï¼š{"App Storeã€Google Play" if len(stores) > 1 else list(stores)[0]}
- è¦†ç›–åœ°åŒºï¼š{len(regions)} ä¸ªï¼ˆ{"ã€".join(sorted(regions))}ï¼‰
- æ€»è®°å½•æ•°ï¼š{total} æ¡

**å„åœ°åŒº Top5 ä¸€è§ˆ**
"""
    # æ ¼å¼åŒ–ä¸ºå¯è¯»è¡¨æ ¼æ–‡æœ¬
    lines = []
    from collections import defaultdict
    groups = defaultdict(list)
    for app in chart_data:
        key = (app.get("store", ""), app.get("chart_name", ""), app.get("region_name", ""))
        groups[key].append(app)

    store_order = {"appstore": 0, "google_play": 1}
    chart_order = {"å…è´¹æ¸¸æˆæ¦œ": 0, "ä»˜è´¹æ¸¸æˆæ¦œ": 1, "ç•…é”€æ¦œ": 2}
    sorted_keys = sorted(
        groups.keys(),
        key=lambda k: (store_order.get(k[0], 9), chart_order.get(k[1], 9), k[2])
    )

    current_store = ""
    current_chart = ""
    for store, chart_name, region in sorted_keys:
        store_label = "App Store" if store == "appstore" else "Google Play"
        if store_label != current_store or chart_name != current_chart:
            lines.append(f"\n**{store_label} Â· {chart_name}**")
            current_store = store_label
            current_chart = chart_name

        apps = sorted(groups[(store, chart_name, region)], key=lambda x: x.get("rank", 999))[:5]
        top5 = "ã€".join([f"#{a['rank']}{a['name']}" for a in apps])
        lines.append(f"- {region}ï¼š{top5}")

    return header + "\n".join(lines)


def generate_weekly_summary(all_week_changes: list[dict], top_charts: list[dict]) -> str:
    """ç”Ÿæˆå‘¨æŠ¥æ‘˜è¦"""
    from collections import Counter
    app_counter = Counter(c["name"] for c in all_week_changes)
    top_movers = app_counter.most_common(10)
    movers_text = "\n".join([f"- ã€Š{name}ã€‹: å‡ºç° {count} æ¬¡å¼‚åŠ¨" for name, count in top_movers])

    region_tops = defaultdict(list)
    for app in top_charts:
        if app.get("rank", 999) <= 3:
            region = app.get("region_name", "")
            region_tops[region].append(f"#{app['rank']} {app['name']}")

    region_text = "\n".join([f"**{r}**: {', '.join(tops)}" for r, tops in region_tops.items()])

    prompt = f"""
æœ¬å‘¨æ‰‹æ¸¸å¸‚åœºæ•°æ®æ‘˜è¦ï¼š

**æœ¬å‘¨å¼‚åŠ¨æœ€é¢‘ç¹çš„æ¸¸æˆï¼š**
{movers_text}

**å„åœ°åŒºå½“å‰ Top3ï¼š**
{region_text}

è¯·ç”Ÿæˆä¸€ä»½ç®€æ´çš„**å‘¨æŠ¥**ï¼ˆçº¦600å­—ï¼‰ï¼ŒåŒ…å«ï¼š
1. **æœ¬å‘¨å¸‚åœºæ€»ç»“**ï¼ˆæ•´ä½“è¶‹åŠ¿ï¼Œ2-3æ®µï¼‰
2. **é‡ç‚¹å…³æ³¨äº§å“**ï¼ˆ3-5æ¬¾å€¼å¾—æŒç»­è·Ÿè¸ªçš„æ¸¸æˆåŠåŸå› ï¼‰
3. **ä¸‹å‘¨é¢„åˆ¤**

è¯­è¨€ï¼šä¸­æ–‡ï¼ŒMarkdown æ ¼å¼ï¼Œé€‚åˆå‘é€ç»™æ¸¸æˆå…¬å¸äº§å“/å¸‚åœºå›¢é˜Ÿé˜…è¯»ã€‚
"""
    system = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ‰‹æ¸¸å¸‚åœºå‘¨æŠ¥åˆ†æå¸ˆã€‚"
    return call_minimax(prompt, system)
